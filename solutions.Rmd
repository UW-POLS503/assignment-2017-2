---
title: 'POLS 503: Assigment 2'
date: '2017-04-21'
output:
  md_document: default
  html_document:
    includes:
      before_body: includes/before_body.html
  pdf_document:
    includes:
      in_header: includes/in_header.tex
    keep_tex: yes
bibliography: assignment2.bib
---


This assignment works through an example in @Yule1899a:

@Yule1899a is a published example multiple regression analysis in its modern form.[^yule]

Yule wrote this paper to analyze the effect of policy changes and implementation on pauperism (poor receiving benefits) in England under the [English Poor Laws](https://en.wikipedia.org/wiki/English_Poor_Laws). In 1834, a new poor law was passed that established a national welfare system in England and Wales. The New Poor Law created new administrative districts (Poor Law Unions) to adminster the law. Most importantly, it attempted to standardize the provision of aid to the poor. There were two types of aid provided: in-relief or aid provided to paupers in workhouses where they resided, and out-relief or aid provided to paupers residing at home. The New Poor Law wanted to decrease out-relief and increase in-relief in the belief that in-relief, in particular the quality of life in workhouses, was a deterrence to poverty and an encouragement for the poor to work harder to avoid poverty.

Yule identifies that there are various potential causes of the change in rate of pauperism, including changes in the (1) law, (2) economic conditions, (3) general social character, (4) moral character, (5) age distribution of the population (pg. 250).

He astutely notes the following:

> If, for example, we should find an increase in the proportion of out-relief associated with (1) an increase in the proportion of the aged to the whole population, and also (2) an increase in the rate of pauperism, it might be legitimate to interpret the result in the sense that changes in out-relief and pauperism were merely simultaneous concomitants of changes in the proportion of aged-the change of pauperism not being a direct consequence of the change of administration, but both direct consequenices of the change in age distribution. It is evidently most important that we should be able to decide between two such differenit ilnterpretations of the same facts. This the method I have used is perfectly competernt to do --- @Yule1899a [pg. 250]

[^yule]: See @Freedman_1997, @Stigler1990a, @Stigler2016a, and @Plewis2017a for discussions of @Yule1899a.

# Setup

```{r message=FALSE}
library("tidyverse")
library("modelr")
```

While only a subset of the original data of @Yule1899a was printed in the article itself, @Plewis2015a reconstructed the orginal data and @Plewis2017a replicated the original paper. This data is included in the package **datums**. This package is not on CRAN, but can be downloaded from github.
**IMPORTANT** install the latest version of **datums** since a few fixes were recently made to the `pauperism` dataset.
```{r}
# devtools::install_github("jrnold/datums")
library("datums")
```

The data for @Yule1899a is split into two data frames: `pauperism_plu` contains data on the Poor Law Unions (PLU), and `pauperism_year`, panel data with the PLU-year as the unit of observation.
```{r}
pauperism <-
  left_join(datums::pauperism_plu, datums::pauperism_year,
            by = "ID")
```
The data consist of `r length(unique(pauperism$ID))` PLUs and the years: 1871, 1881, 1891 (years in which there was a UK census).

@Yule1899a is explcitly using regression for causal inference. The outcome variable of interest is:

- **Pauperism** the percentage of the population in receipt of relief of any kind, less lunatics and vagrants

The treatment (policy intervention) is the ration of numbers receiving outdoor relief to those receiving indoor relief.

- **Out-Relief Ratio:** the ratio of numbers relieved outdoors to those relieved indoors

He will control for two variables that may be associated with the treatment

- **Proportion of Old:** the proportion of the aged (65 years) to the whole population since the old are more likely to be poor.
- **Population:** in particular changes in population that may be proxying for changes in the economic, social, or moral factors of PLUs.

There is also **Grouping of Unions**, which is a locational classification based on population density that consists of Rural, Mixed, Urban, and Metropolitan.

Instead of taking differences or percentages, Yule worked with "percent ratio differences", $100 \times \frac{x_{t}}{x_{t-1}}$, because he did not want to work with negative signs, presumably a concern at the because he was doing arithmetic by hand and this would make calculations more tedious or error-prone.


## Original Specification

Run regressions of `pauper` using the yearly level data with the following specifications. 
In @Yule1899a, the reg

- *M1:* `paupratiodiff ~ outratiodiff + year + Type`
- *M2:* `paupratiodiff ~ outratiodiff + (popratiodiff + oldratiodiff) * (year + Type)`
- *M3:* `-1  + paupratiodiff ~ (outratiodiff + popratiodiff + oldratiodiff) * (year + Type)`
- *M4:* `paupratiodiff ~ (outratiodiff + popratiodiff + oldratiodiff) * (year + Type)`

```{r}
# Year should be a categorical
pauperism$year <- as.factor(pauperism$year)
M1.reg <- lm(paupratiodiff ~ outratiodiff + year + Type, data=pauperism)
M2.reg <- lm(paupratiodiff ~ outratiodiff + (popratiodiff + oldratiodiff) * (year + Type), data=pauperism)
M3.reg <- lm(-1  + paupratiodiff ~ (outratiodiff + popratiodiff + oldratiodiff) * (year + Type), data=pauperism)
M4.reg <- lm(paupratiodiff ~ (outratiodiff + popratiodiff + oldratiodiff) * (year + Type), data=pauperism)
```


# 1. Present the regressions results in a regression table
```{r}
library("texreg")
models <- list(M1.reg, M2.reg, M3.reg, M4.reg)
htmlreg(models)
htmlreg(models, file = "models.html")
library("htmltools")
htmlreg(models) %>% HTML() %>% browsable()
```


# 2. Interpret the coefficients for `outratiodiff` for each model.

```{r}
summary(M1.reg)
unique(pauperism$year)
```
M1 <- There are 5 independent variables, outratiodiff, year1891, TypeMixed, TypeRural, and TypeUrban. For each one unit increase in outratio diff, there is a .23 average unit increase in paupratiodiff, ceteris paribus. Year is a categorical variable. Year1881 is the reference category, and the coefficient on Year1891 denotes a 14.70 increase in the mean of Y in 1891 vs. in 1881. Type is in a categorical variable, in which the Metropolitan type is being used as the reference variable. The coefficients denoting the difference in paupratio in the different types, when compared to the reference category. For instance, there is a decrease of 6.45 in the paupratio among people in the Mixed Type vs. people in the Metropolitan Type. The intercept coefficient denotes a paupratiodiff of 56.71, meaning that the paupratiodiff is 56.71 when all of the independent variables are 0.

```{r}
summary(M2.reg)
```

M2 <- The interpretation of M2 is simalar to M1 in some ways. For instance, for each one unit increase in outratiodiff, there is a .23 average unit increase in paupratiodiff and the intercept coefficient denotes a paupratiodiff of -55.34, meaning that the paupratiodiff is -55.34 when all of the independent variables are 0. The coefficients on year and the Type variables are interpreted in the same way as they were interpreted in M1 as well. 

There is a key difference between M1 and M2; the inclusion of the interaction terms in M2. There are interaction terms for popratiodiff and year, popratiodiff and Type, oldratiodif and year, and oldratiodiff and Type. Type and year are categorical variables, so we create dummies from the values in each. For popratiodiff*Type, there are coefficients for popratiodiff*TypeMixed, popratiodiff*TypeRural, and popratiodiff*TypeUrban. I'm going to use popratiodiff*TypeMixed as an example, but the intuition holds for the other terms. Where TypeMixed is 0 (i.e. the person doesn't live in a Mixed PLU), the interaction term drops out of the equation. When TypeMixed is 1, the slope of the fitted value equation decreases by about .00237 (the coefficient is -2.372e-02). We can interpret all of the other interaction terms including Type and year similarly.


```{r}
summary(M3.reg)
```

M3 <- There are similarities between M3 and M1 and M2. For each one unit increase in outratiodiff, there is a .53 average unit increase in paupratiodiff. The intercept coefficient denots a paupratiodiff of 6.17, meaning that the paupratiodiff is 6.17 when all of the independent variables are 0.

M3 is different from M2 in 2 ways 1) there is an affine transformation on the dependent variable and 2) interaction terms are now included on outratiodiff and year as well as type. We can interpret the new interaction terms similarly as we did in M2. The affine transformation affects the intercept (more details on affine transformations provided in my answer to question 4).

```{r}
summary(M4.reg)
```

M4 <- There are similarities For each one unit increase in outratiodiff, there is a .53 average unit increase in paupratiodiff. The intercept coefficient denots a paupratiodiff of 7.17, meaning that the paupratiodiff is 7.17 when all of the independent variables are 0.

M4 is the same as M3 except the affine transformation is not included. The affine transformation affects the intercept (more details on affine transformations provided in my answer to question 4).

# 3. Write the equations for each or all models, and describe the model with a sentence or two. Try to be as concise as possible. Look at recent journal articles for examples of the wording and format.

```{r}
summary(M1.reg)
```

The M1 equation is:
\[
paupratiodiff_i = B_0 + B_1outratiodiff_i + year_i + TypeMixed_i + TypeRural_i + TypeUrban_i + \epsilon
\]
where \[B_0\] is the intercept, estimating the paupratiodiff when all independent variables are 0, \[B_1outratiodiff_i\] is the estimated change in paupratiodiff associated with a one unit increase in outratiodiff,  \[year_i\] is the estimated change in the dependent variable associated with a one-unit increase in year, the Type variables are dummy variables indicating whether the respondent lives in one of the three regions (if all of the variables are 0, then the respondent lives in the reference category, which is the Metropolitan PLU), and \[\epsilon\] is the error term, denoting the inability of our conditional expectation function to fully explain Y.

```{r}
summary(M2.reg)
```

The M2 equation is:
\[
paupratiodiff_i = B_0 + B_1outratiodiff_i + popratiodiff_i + oldratiodiff_i + year_i + TypeMixed_i + TypeRural_i + TypeUrban_i + popratiodiff*year + popratiodiff*TypeMixed + popratiodiff*TypeRural + popratiodiff*TypeUrban + oldratiodiff*year + oldratiodiff*TypeMixed + oldratiodiff*TypeRural + oldratiodiff*TypeUrban + \epsilon
\]
where \[B_0\] is the intercept, estimating the paupratiodiff when all independent variables are 0, \[B_1outratiodiff_i\] is the estimated change in paupratiodiff associated with a one unit increase in outratiodiff,  \[year_i\] is the estimated change in the dependent variable associated with a one-unit increase in year, \[Type_i\] is a categorical variable denoting the change in Y associated with different categories of type, and \[\epsilon\] is the error term, denoting the inability of our conditional expectation function to fully explain Y. There are also interaction terms associated with this model -- popratiodiff*year, oldratiodiff*year, popratiodiff*Type, and oldratiodiff*Type. 

The M3 equation is:
\[
1 -paupratiodiff_i = B_0 + B_1outratiodiff_i + popratiodiff_i + oldratiodiff_i + year_i + TypeMixed_i + TypeRural_i + TypeUrban_i + popratiodiff*year + popratiodiff*TypeMixed + popratiodiff*TypeRural + popratiodiff*TypeUrban + oldratiodiff*year + oldratiodiff*TypeMixed + oldratiodiff*TypeRural + oldratiodiff*TypeUrban + outratiodiff*year + outratiodiff*TypeMixed + outratiodiff*TypeRural + outratiodiff*TypeUrban + \epsilon
\]
which is the same equation as M2, except there are now interaction terms for outradtiodiff and year and Type, as well as the affine transformation applied to the dependent variable. 

The M4 equation is:
\[
paupratiodiff_i = B_0 + B_1outratiodiff_i + popratiodiff_i + oldratiodiff_i + year_i + TypeMixed_i + TypeRural_i + TypeUrban_i + popratiodiff*year + popratiodiff*TypeMixed + popratiodiff*TypeRural + popratiodiff*TypeUrban + oldratiodiff*year + oldratiodiff*TypeMixed + oldratiodiff*TypeRural + oldratiodiff*TypeUrban + outratiodiff*year + outratiodiff*TypeMixed + outratiodiff*TypeRural + outratiodiff*TypeUrban + \epsilon
\]
The equation is the same as M3, but there is no affine transformation.


4. What is the difference between *M3* and *M4*. What are the pros and cons of each parameterization?

M3 has an affine transformation, which slightly changes the intercept. Affine transformation are beneficial for interpretation sometimes, though it does not seem that an affine transformation was beneficial in this case. If we want to transform our data to get more sensical results, sometimes we can apply an affine transformation. Affine transformations do not change the interpretation of regression results.

5. Conduct F-tests on the hypotheses:

  1. All interactions in *M4* are 0
```{r}
restricted1 <- lm(paupratiodiff ~ (outratiodiff + popratiodiff + oldratiodiff), data=pauperism)
anova(M4.reg, restricted1)
```  
The small p-value indicate that we can and should reject the null hypothesis that all of the interaction betas are 0.

#### 2. Just asking if all of the interactions between outratio diff and years are 0.
# TODO: Ask for help on this question

  2. The coefficients on `outratiodiff` in *M4* are the same across years]
```{r}
restricted2 <- lm(paupratiodiff ~ outratiodiff + (popratiodiff + oldratiodiff) * (Type + year), data=pauperism)
anova(M4.reg, restricted2)
```  

  3. The coefficients on `outratiodiff` in *M4* are the same across PLU Types
The anova command generates results indicating that Type is not 0, and therefore outratio diff is not the same across all years, since controlling for year has an effect.
```{r}
restricted3 <- lm(paupratiodiff ~ (outratiodiff + popratiodiff + oldratiodiff) * (year), data=pauperism)
anova(M4.reg, restricted3)
```

#### 4 and 1 are the same, except outratiodiff is the only term that we're using in M4. If you can reject the null in 4, it would imply that you can reject the null in M1, but not the other way around
  4. The coefficients on `outratiodiff` in *M4* are the same across PLU Types and years.
```{r}
restricted4 <- lm(paupratiodiff ~ (outratiodiff + popratiodiff + oldratiodiff), data=pauperism)
anova(M4.reg, restricted4)
```



# 6. Calculate the predicted value and confidence interval for the PLU with the median value of outratiodiff, popratiodiff, and oldratiodiff in each year and PLU Type for these models. Plot the predicted value and confidence interval of these as point-ranges.

Use the predict function and pass a matrix of independent values into the matrix. One column for each X.

# Check the code from the first lab for help in doing this question
# Another option is to use the predict function with the newdata argument specified
# Broom package is helpful in cleaning up the output of predict (augment.lm)

```{r}
plu_medians <- pauperism %>% group_by(year, Type)  %>%
  filter(!is.na(Type), year %in% c(1881, 1891)) %>%
  summarise_at(vars(outratiodiff, popratiodiff, oldratiodiff),
               median, na.rm=TRUE)

library("broom")
augment(M4.reg, newdata = plu_medians, conf.int=TRUE, conf.level=.95)
predictions_ci <- predict(M4.reg, newdata = plu_medians, interval="confidence", conf.level=.95)

predictions_ci
# to plot, need to bind cols plu_medians and plu_predictions
# do this for a bunch of different models
# what's the difference between a confidence interval and prediction interval? CI is a measure of our uncertainty about the conditional mean (y-hat). Prediction interval is the measure of the uncertainty in the actual ys given x. CEF gives us the expeced value of Y given X. Prediction interval is basically the uncertainty associated with the expected value of y + the uncertainty regarding the actual values of y, given X. 
```

7. As previously, calculate the predicted value of the median PLU in each year and PLU Type. But instead of confidence intervals include the prediction interval. How do the confidence and prediction intervals differ? What are their definitions?

```{r}
predictions_pi <- predict(M4.reg, newdata = plu_medians, interval="prediction", conf.level=.95)
predictions_pi
```

TODO --> Do predictions for all models and put output into a table.

Confidence intervals measure the uncertainty around the mean estimated by the conditional expectation function (E(Y|X)). Prediction intervals are always wider than confidence intervals, since they account for the uncertainty surrounding the predicted y as well as the uncertainty around the actual Y values, given X (Y|X).  

The equation for a confidence interval is: V(y^)=σ^x′0(X′X)−1x. The equation for a predication interval is V(y)=σ^2(1+x′0(X′X)−1x0). The difference between the 2 equations is the addition of the variance of the regression as well as the replacement of the standard error of the regression in the confidence interval equation with the the variance of the regression in the prediction interval equation. 

Citations -- https://www.ma.utexas.edu/users/mks/statmistakes/CIvsPI.html and intro methods notes


## Functional Forms

# Look through functional forms --> take the logs of everything

The regression line of the model estimated in @Yule1899a (ignoring the year and region terms and interactions) can be also written as
$$
\begin{aligned}[t]
100 \times \frac{\mathtt{pauper2}_t / \mathtt{Popn2_t}}{\mathtt{pauper2}_{t-1} / \mathtt{Popn2_{t-1}}} 
&= \beta_0 + \beta_1 \times 100 \times \frac{\mathtt{outratio}_t}{\mathtt{outratio_{t-1}}} \\
& \quad + \beta_2 \times 100 \times \frac{\mathtt{Popn65}_t / \mathtt{Popn2}_{t}}{\mathtt{Popn65}_{t-1} / \mathtt{Popn2}_{t-1}} + \beta_3 \times 100 \times \frac{\mathtt{Popn2}_t}{\mathtt{Popn2}_{t - 1}}
\end{aligned}
$$

1. Take the logarithm of each side, and simplify so that $\log(\mathtt{pauper2}_t/\mathtt{pauper2}_{t -1})$ is the outcome and the predictors are all in the form $\log(x_t) - \log(x_{t - 1}) = \log(x_t / x_{t - 1})$.

# Do format like below
$\log(\mathtt{pauper2}_t)-\log(\mathtt{pauper2}_{t -1}) = \beta_0 + \beta_1 \times (log(pop_t) - log(pop_{t-1}))$

$\log(\mathtt{pauper2}_t)-\log(\mathtt{pauper2}_{t -1}) = [\beta_0 + \beta_1 \times 100 \times \log(outratio_t) - \log(outratio_{t-1} + \beta_2 \times 100 \times \log(Popn65_t)-log(Popn65_{t-1})-log(Popn2_t)-log(Popn2_{t-1}) \times \beta_3 \times 100 \times \log(Popn2_t)-log(Popn2_{t-1}) + log(Popn2_t)-log(Popn2_{t-1})]/100$

2. Estimate the model with logged difference predictors, Year, and month and interpret the coefficient on $\log(outratio_t)$.
```{r}
# need to get the lag on pauper
# do this by creating dfs with only 1881 values and 1891 values, then join them by ID
paup1881 <- pauperism %>% filter(year==1881)
paup1881$pauper2t_minus_1 <- paup1881$pauper2
paup1881$outratio_t_minus_1 <- paup1881$outratio
paup1881$Prop65_t_minus_1 <- paup1881$Prop65
paup1881$Popn2_t_minus_1 <- paup1881$Popn2

paup1891 <- pauperism %>% filter(year==1891)
paup1891$pauper2t <- paup1891$pauper2
paup1891$outratio_t <- paup1891$outratio
paup1891$Prop65_t <- paup1891$Prop65
paup1891$Popn2_t <- paup1891$Popn2

M5data <- inner_join(paup1881, paup1891, by="ID")

M5.reg <- lm((log(pauper2t) - log(pauper2t_minus_1))~log(outratio_t)-log(outratio_t_minus_1) + log(Prop65_t) - log(Prop65_t_minus_1) + log(Popn2_t) - log(Popn2_t) + log(Popn2_t) - log(Popn2_t), data=M5data)

summary(M5.reg)
```
M5 is a log-log model that allows us to estimate elasticity. For each 1% increase in the first difference (the difference between $outratio_t$ and $outratio_{t-1}$), there is a .8% increase in the dependent variable (the difference betweeen $pauper2_t$ and $pauper2_{t-1}$.

3. What are the pros and cons of this parameterization of the model relative to the one in @Yule1899a? Focus on interpretation and the desired goal of the inference rather than the formal tests of the regression. Can you think of other, better functional forms?

The pros of the log parameterization are that logging variables allows for me to interpret the change in the independent/dependent variables as percentage changes as opposed to unit changes. I think that the key benefit of the change is interpretability.

# Question: Does estimating the first difference remove the autocorrelation concerns?

A negative of using log-models in this case is that we could get negative values (e.g. $outratio_t-outratio_{t-1}$ could be negative) and it is not possible to produce a logged value of negative numbers.

# TODO: Ask about the best way to determine functional form
Using a log-log model isn't a great functional form for this data, since there are negative values in the independent and dependent variables. Using a linear-linear model, and removing some of the outliers, seems like it would be a better functional form for estimating this data.
```{r}
qplot(outratio_t - outratio_t_minus_1, pauper2t - pauper2t_minus_1, data=M5data)
```


## Non-differenced Model

Suppose you estimate the model (*M5*) without differencing,
```
pauper2 ~ outratio + (Popn2 + Prop65) * (year + Type)
```
```{r}
M6.reg <- lm(pauper2 ~ outratio + (Popn2 + Prop65) * (year + Type), data=pauperism)
summary(M6.reg)
```

- Interpret the coefficient on `outratio`. How is this different than model *M5*
There are a few differences. Our independent variables are no longer the change in the independent variable over time, but rather are the actual values in the specific time periods. M6 also does not estimate elasticity, but rather the change in Y for each unit change in X.

- What accounts for the different in sample sizes in *M5* and *M2*?
```{r}
nrow(model.frame(M6.reg))
# [1] 1773
nrow(model.frame(M5.reg))
# [1] 592
```
In M5, there are fewer data points because we are looking at the change in each independent variable. Therefore, we take two rows worth of data to produce one data point. In M6, we have more data because each row is its own data point.

- What model do you think will generally have less biased estimates of the effect of out-relief on pauperism: *M5* or *M2*? Explain your reasoning.
M5 will be more biased, since we cannot use a lot of negative data points when we log our independent and dependent variables to generate our estimates.


## Substantive Effects

Read @Gross2014a and @McCaskeyRainey2015a. Use the methods described in those papers to assess the substantive effects of out-ratio on the rate of pauperism. Use the model(s) of your choosing.


## Influential Observations and Outliers

### Influential Observations for the Regression

For this use *M2*:

1. For each observation, calculate and explain the following:

  - hat value (`hatvalues`)
  - standardized error (`rstandard`)
  - studentized error  (`rstudent`)
  - Cook's distance (`cooksd`)

2. Create an outlier plot and label any outliers. See the example [here](https://jrnold.github.io/intro-methods-notes/outliers.html#iver-and-soskice-data)
3. Using the plot and rules of thumb identify outliers and influential observations


## Influential Observations for a Coefficient

1. Run *M2*, deleting each observation and saving the coefficient for `outratiodirff`. This is a method called the jackknife. You can use a for loop to do this, or you can use the function `jackknife` in the package [resamplr](https://github.com/jrnold/resamplr).
  
    - For which observations is there the largest change in the coefficient on `outratiodiff`?
    1. Which observations have the largest effect on the estimate of `outratiodiff`? 
    2. How do these observations compare with those that had the largest effect on the overall regression as measured with Cook's distance?
    3. Compare the results of the jackknife to the `dfbeta` statistic for `outratiodiff`

2. @AronowSamii2015a note that the influence of observations in a regression coefficient is different than the the influence of regression observations in the entire regression. Calculate the observation weights for `outratiodiff`.

    1. Regress `outratiodiff` on the control variables
    2. The weights of the observations are those with the highest squared errors from this regression. Which observations have the highest coefficient values? 
    3. How do the observations with the highest regression weights compare with those with the highest changes in the regression coefficient from the jackknife?


## Omitted Variable Bias

An informal way to assess the potential impact of omitted variables on the coeficient of the variable of interest is to coefficient variation when covariates are added as a measure of the potential for omitted variable bias [@Oster2016a].
@NunnWantchekon2011a (Table 4) calculate a simple statistic for omitted variable bias in OLS. This statistic "provide[s] a measure to gauge the strength of the likely
bias arising from unobservables: how much stronger selection on unobservables,
relative to selection on observables, must be to explain away the full estimated
effect."

1. Run a regression without any controls. Denote the coefficient on the variable of interest as $\hat\beta_R$.
2. Run a regression with the full set of controls. Denote the coefficient on the variable of interest in this regression as $\hat\beta_F$. 
3. The ratio is $\hat\beta_F / (\hat\beta_R - \hat\beta_F)$

Calculate this statistic for *M2* and interpret it.


## Heteroskedasticity

1. Run *M2* and *M3*  with a heteroskedasticity consistent (HAC), also called robust, standard error. How does this affect the standard errors on `outratio` coefficients? Use the **sandwich** package to add HAC standard errors [@Zeileis2004a].
2. Model *M3* is almost equivalent to running separate regressions on each combination of `Type` and `Year`. 

    1. Run a regression on each subset of combination of `Type` and `Year`.
    2. How do the coefficients, standard errors, and regression standard errors ($\sigma$) differ from those of *M3*.
    3. Compare the robust standard errors in *M3* to those in the subset regressions. What is the relationship between heteroskedasticity and difference between the single regression with interactions (*M3*) and the multiple regressions.
    


## Weighted Regression

1. Run *M2* and *M3* as weighted regressions, weighted by the population (`Popn`) and interpret the coefficients on `outratiodiff` and interactions. Informally assess the extent to which the coefficients are different. Which one does it seem to affect more? 
2. What are some rationales for weighting by population? See the discussion in @SolonHaiderWooldridge2013a and @AngristPischke2014a.


**BELOW THIS STILL IN PROGRESS**

## Average Marginal Effects



## Cross-Validation

When using regression causal estimation, model specification and choice should largely be based on avoiding omitted variables. 
Another criteria for selecting models is to use their fit to the data.
But a model's fit to data should not be assessed using only the in-sample data.
That leads to overfitting---and the best model would always be to include an indicator variable for every observation
Instead, a model's fit to data can be assessed by using its out-of-sample fit.
One way to estimate the *expected* fit of a model to *new* data is cross-validation.



## Bootstrapping

Estimate the 95% confidence intervals of model with simple non-parametric bootstrapped standard errors. The non-parametric bootstrap works as follows:

Let $\hat\theta$ be the estimate of a statistic. To calculate bootstrapped standard errors and confidence intervals use the following procedure.

For samples $b = 1, ..., B$.

1. Draw a sample with replacement from the data
2. Estimate the statistic of interest and call it $\theta_b^*$.

Let $\theta^* = \{\theta_1^*, \dots, \theta_B^*\}$ be the set of bootstrapped statistics.

- standard error: $\hat\theta$ is $\sd(\theta^*)$.
- confidence interval:

    - normal approximation. This calculates the confidence interval as usual but uses the bootstrapped standard error instead of the classical OLS standard error: $\hat\theta \pm t_{\alpha/2,df} \cdot \sd(\theta^*)$
    - quantiles: A 95% confidence interval uses the 2.5% and 97.5% quantiles of $\theta^*$ for its upper and lower bounds.

    
## References
